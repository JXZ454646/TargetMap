{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('allData.csv')\n",
    "filtered_df_A = df[(df['DATABASEA'] == 'UNIPROT') | (df['DATABASEA'] == 'ChEBI')]\n",
    "filtered_df_B = df[(df['DATABASEB'] == 'UNIPROT') | (df['DATABASEB'] == 'ChEBI')]\n",
    "entity_id_dict = {row['IDA']: row['ENTITYA'] for _, row in filtered_df_A.iterrows()}\n",
    "entity_id_dict.update({row['IDB']: row['ENTITYB'] for _, row in filtered_df_B.iterrows()})\n",
    "entity_id_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('entity_id_dict.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(entity_id_dict, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all.txt', 'w') as f:\n",
    "    for row in df.itertuples():\n",
    "        f.write(f'{row.IDA}\\t{row.MECHANISM}\\t{row.IDB}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_file = \"all.txt\"\n",
    "train_file = \"train.txt\"\n",
    "valid_file = \"valid.txt\"\n",
    "test_file = \"test.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "train_data, temp_data = train_test_split(lines, test_size=0.2, random_state=42)  # 80% train, 20% temp\n",
    "valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)  # 10% valid, 10% test\n",
    "\n",
    "with open(train_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(train_data)\n",
    "\n",
    "with open(valid_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(valid_data)\n",
    "\n",
    "with open(test_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransE\n",
    "DGLBACKEND=pytorch dglke_train --dataset test4 --model_name TransE_l2 --batch_size 1024 --neg_sample_size 512 --hidden_dim 1024 --gamma 19.9 --lr 0.01 --max_step 200000 --log_interval 100 --batch_size_eval 1024 -adv --regularization_coef 1.00E-09 --test --valid --num_thread 8 --gpu 0  --save_path ./test4 --data_path ./test4 --format raw_udd_hrt --data_files train.txt valid.txt test.txt\n",
    "\n",
    "# model_name can be \"TransE_l2\", \"ComplEx\", \"RotatE\", \"DistMult\", \"TransR\", \"RESCAL\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
